{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a564d5f",
   "metadata": {},
   "source": [
    "#  Сегментация изображений\n",
    "\n",
    "__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n",
    "\n",
    "Материалы: \n",
    "* https://www.kaggle.com/datasets/rajkumarl/people-clothing-segmentation/data\n",
    "* https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/\n",
    "* https://amaarora.github.io/posts/2020-09-13-unet.html\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html\n",
    "* https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8\n",
    "* https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "* https://huggingface.co/docs/transformers/model_doc/segformer\n",
    "* https://www.kaggle.com/code/damianpanek/segformerb0-people-clothing-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecd663",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0a45b-6d8e-43d8-8c39-c24c10e966e8",
   "metadata": {},
   "source": [
    "1\\. Рассмотрите пример работы слоя `ConvTranspose2d`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b6d63",
   "metadata": {},
   "source": [
    "## Задачи для самостоятельного решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49190d",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"1\"></p>\n",
    "\n",
    "1\\. Опишите датасет `ClothesSegmentationDataset`. Реализуйте `__getitem__` таким образом, чтобы он возвращал два элемента: тензор с изображением и тензор с маской. Маска должна быть представлена трехмерным тензором целых чисел. Предусмотрите возможность передавать извне при создании датасета набор преобразований для изображений и масок. Создайте объект датасета и выведите на экран форму и типы одного изображения и его маски.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c810ae",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"2\"></p>\n",
    "\n",
    "2\\. Напишите функцию `show_image_with_mask`, которая выводит рядом два изображения: фотографию и маску. Продемонстрируйте работу функции, взяв один пример из созданного датасета.\n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde13cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_mask(image, mask):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac36cf",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"3\"></p>\n",
    "\n",
    "3\\. Реализуйте архитектуру U-Net. Реализуйте модель таким образом, чтобы на выходе для каждого изображения получался тензор размера `n_classes x h x w`, где `n_classes` - количество уникальных значений в масках, а `h` и `w` - размер исходного изображения. Возьмите один пример из набора данных и пропустите его через сеть. Выведите форму полученного результата на экран. \n",
    "\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa68b88",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"4\"></p>\n",
    "\n",
    "4\\.  Разбейте набор данных на обучающее и валидационное множество. Обучите модель U-Net для сегментации изображения. Во время обучения выводите на экран значения функции потерь и точности прогнозов на обучающем и валидационном множестве. Обратите внимание, что выборка является несбалансированной. При расчете функции потерь примените любую известную вам технику для работы с несбалансированными выборками. \n",
    "\n",
    "При создании датасета допускается использовать преобразования, уменьшающие размер изображений (для ускорения процесса обучения). \n",
    "\n",
    "Используя обученную модель, получите предсказания для нескольких изображений и отрисуйте их.\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a9ea1f",
   "metadata": {},
   "source": [
    "<p class=\"task\" id=\"5\"></p>\n",
    "\n",
    "5\\.  Обучите модуль `SegformerForSemanticSegmentation` из пакета `transformers` для сегментации изображения. Во время обучения выводите на экран значения функции потерь и точности прогнозов на обучающем и валидационном множестве. Для оптимизации используйте значение функции потерь, которое возвращает вам модель.\n",
    "\n",
    "Используя обученную модель, получите предсказания для нескольких изображений и отрисуйте их.\n",
    "- [ ] Проверено на семинаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559b200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
